# mysql
* 创建RDD，这个RDD会记录之后数据从哪里读取
* 指定的分区后，会将数据进行切分并将每个分区中的最大，最小值传入到sql中进行过滤,所以使用<= >=
![image](https://github.com/wjn0918/Study/blob/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/images/apache/spark/jdbcRDD.png)
```
val getConnect = () => {
    DriverManager.getConnection("")
}


new JdbcRDD(
    sc:SparkContext,   //spark 上下文
    getConnect: () ⇒ Connection,    //jdbc连接
    "select title, author from books where ? <= id and id <= ?":String,   //Sql 语句
    lowerBound:Long,  //最小值
    upperBound:Long,  //最大值
    numPartitions:Int,  //分区
    //结果集
    rs: ResultSet =>{
        val title = rs.getString(1)
        val author = rs.getString(2)
    }  
    (title,author)
)
```